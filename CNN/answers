# Write your short answers in this file, replacing the placeholders as appropriate.
# This assignment consists of 3 parts for a total of 114 points.
# - Exploration (39 points)
# - Neural Bag of Words (41 points)
# - Convolutional Neural Networks (34 points)
#
# NOTE:  points for coding sections are often included in the short answers they support.



###################################################################
###################################################################
## Notebook: Exploration (39 points)
###################################################################
###################################################################


# ------------------------------------------------------------------
# | Section (a): Exploring the Data (16 points)  | 
# ------------------------------------------------------------------

# Question 1.1 (/1): What is the fraction of positive labels?
exploration_a_1_1: 0.5216763005780347

# Question 1.2 (/1): Is it approximately balanced?
exploration_a_1_2: Yes

***# Question 1.3 (/1): What is the common class accuracy?
exploration_a_1_3: 0.5687288701743021

***# Code for question 1 (/1)


# Question 2 (/5): What are the most common five tokens in the data set?
exploration_a_2: 
- the
- a
- and
- of
- to

# Code for question 2 (/1)

# Question 3 (/1): What is the 95th percentile sentence length?
exploration_a_3: range(1.0372615279470914, 37.56244945471187)

# Code for question 3 (/2)

# Question 4.1 (/1): What is the 95th percentile including subphrases?
exploration_a_4_1: range(-7.69242167686791, 22.727626243946883)

# Question 4.2 (/1): Why might this be problematic? 
# This question is a candidate for discussion in live session.

exploration_a_4_2: Yes, this might be problematic. Because there is high chances that subphrases won't be completely meaningful for classifier to correctly predict the positive or negative sentiment. So sentiment analysis will be (no necessarily) more faulty.

# Code for question 4 (/1)


# ------------------------------------------------------------------
# | Section (b): Naive Bayes (10 points)  | 
# ------------------------------------------------------------------

# Code for question 1 (/2)

# Question 2.1 (/1): What is the most positive word?
exploration_b_2_1: powerful

# Question 2.2 (/1): What is the most positive word's score?
exploration_b_2_2: 3.53

# Question 2.3 (/1): What is the most negative word?
exploration_b_2_3: stupid

# Question 2.4 (/1): What is the most negative word's score?
exploration_b_2_4: -3.17

# Code for question 2 (/3)

# Question 2.5 (/1): Do your words make sense for this domain?  Why or why not?
# This question is a candidate for discussion in live session.

exploration_b_2_5: Yes it does. It correctly analyse sentiment to get positive words and negative words.


# ------------------------------------------------------------------
# | Section (c): Examining Negation (13 points)  | 
# ------------------------------------------------------------------

# Question 1.1 (/1): Why does it get the first one wrong?
# This question is a candidate for discussion in live session.

exploration_c_1_1: In first sentence there is only one negative word 'short'. However, there is multiple positive words like 'high', 'standards', 'performance'. Therefore the linear model predicts the whole sentence as a positive sentiment, though actually it is negative.

# Question 1.2 (/1): Why does it get the second one right?
# This question is a candidate for discussion in live session.

exploration_c_1_2: In the second sentence there is just one positive 'thoughtful' and one negative 'painful' word. However, the positive word is much stronger (4 rating) than the negative one is (1. 0 would have been much stronger negative).
So the overall sentiment is derived as positive. And in this case it is right.

# Question 2.1 (/1): What patterns do you see?
# This question is a candidate for discussion in live session.
exploration_c_2_1: If a whole sentence has greater number of phrases with positive polarity, the sentence;s polarity is also positive and vice versa. But this does not follow always, also fails when most of the phrases have nutral polarity. 

# Question 2.2 (/1): What is the relationship of polarity in these interesting sentences between a subphrase and the whole sentence?
# (This question is multiple choice.  Delete all but the correct answer(s)).
exploration_c_2_2: 

 - opposite

# Question 2.3 (/1): Is this phenomenon captured well by a linear model?
exploration_c_2_3: Not really.

# Question 2.4 (/1): Why or why not?
# This question is a candidate for discussion in live session.
exploration_c_2_4:
Whole sentence is one polarity and the phrase is opposite.

# Code for question 2 (/1)

    display(ds.test_trees[0])
    display(ds.test_trees[577])
    display(ds.test_trees[2063])

# Question 3.1 (/2): What is the error (%) on the whole test set?
exploration_c_3_1: 17.79

# Question 3.2 (/2): What is the error (%) on the interesting part of the test set?
exploration_c_3_2: 26.74

# Question 3.3 (/1): What is the increase in error (as a %)?
exploration_c_3_3: 50.31

# Code for question 3 (/1)


###################################################################
###################################################################
## Notebook: Neural Bag of Words (41 points)
###################################################################
###################################################################


# ------------------------------------------------------------------
# | Section (d): Model Architecture (15 points)  | 
# ------------------------------------------------------------------

# Question 1.1 (/1): What are the dimensions of w_embed?
neural_bag_of_words_d_1_1: [V, d]

# Question 1.2 (/1): What are the dimensions of w_0?
neural_bag_of_words_d_1_2: [d, h1]

# Question 1.3 (/1): What are the dimensions of b_0?
neural_bag_of_words_d_1_3: [h1]

# Question 1.4 (/1): What are the dimensions of w_1?
neural_bag_of_words_d_1_4: [h1, h2]

# Question 1.5 (/1): What are the dimensions of b_1?
neural_bag_of_words_d_1_5: [h2]

# Question 1.6 (/1): What are the dimensions of w_out?
neural_bag_of_words_d_1_6: [h2, k]

# Question 1.7 (/1): What are the dimensions of b_out?
neural_bag_of_words_d_1_7: [k]

# Question 2.1 (/1): How many parameters are there in the embedding layer?
neural_bag_of_words_d_2_1: 21

# Question 2.2 (/2): How many parameters are there in the hidden layers?
neural_bag_of_words_d_2_2: h1 => 7*6+6 = 48, h2 => 6*5+5=35

# Question 2.3 (/1): How many parameters are in the output layer?
neural_bag_of_words_d_2_3: 5*2+2=12

# Question 3.1 (/1): What should you set the embedding dimension, d, to?
neural_bag_of_words_d_3_1: 1

# Question 3.2 (/1): What about the hidden layers?
neural_bag_of_words_d_3_2: [None]

# Question 4.1 (/1): Would these predict the same result?
neural_bag_of_words_d_4_1: False

# Question 4.2 (/1): Why would they (or would they not) predict the same result?
# This question is a candidate for discussion in live session.
neural_bag_of_words_d_4_2: No, prediction won't be same.
I think after tokenizing the sentence the index of 'foo', 'baz' in the first phrase will be different than those in second phrase.


# ------------------------------------------------------------------
# | Section (e): Implementing a neural network (15 points)  | 
# ------------------------------------------------------------------

# Code for question Embedding Layer (/5)

# Code for question Output Layer (/5)

# Code for question BOW Encoder (/5)


# ------------------------------------------------------------------
# | Section (f): Evaluating your model (11 points)  | 
# ------------------------------------------------------------------

# Code for question 1 (/5)

# Question 2.1 (/1): What was the accuracy on the interesting set? (%)
neural_bag_of_words_f_2_1: 70.93

# Question 2.2 (/1): What was the accuracy on the whole set? (%)
neural_bag_of_words_f_2_2: 77

# Question 2.3 (/1): Are these better than Bayes?
neural_bag_of_words_f_2_3: No

# Question 2.4 (/1): Why do you think this might be?
# This question is a candidate for discussion in live session.
neural_bag_of_words_f_2_4: whole sentences are usually the opposite polarity of the majority of its subphrases

# Question 3 (/1): Does it require more training time?
neural_bag_of_words_f_3: Yes, I think so.

# Question 4 (/1): Is it overfitting?
neural_bag_of_words_f_4: Yes, I think so



###################################################################
###################################################################
## Notebook: Convolutional Neural Networks (34 points)
###################################################################
###################################################################


# ------------------------------------------------------------------
# | Section (g): CNN Short Answer Questions (model architecture) (16 points)  | 
# ------------------------------------------------------------------

# Question 1.1 (/1): What is the dimension of ck3?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_1_1: [(N-3)+1, 128]

# Question 1.2 (/1): What is the dimension of ck4?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_1_2: [(N-4)+1, 128]

# Question 1.3 (/1): What is the dimension of ck5?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_1_3: [(N-5)+1, 128]

# Question 1.4 (/1): What is the dimension of chatk3?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_1_4: [1, 128]

# Question 1.5 (/1): What is the dimension of chatk4?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_1_5: [1, 128]

# Question 1.6 (/1): What is the dimension of chatk5?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_1_6: [1, 128]

# Question 1.7 (/1): What is the dimension of Chat?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_1_7: [1, 384]

# Question 2.1 (/1): What is the dimension of ck3?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_2_1: [N, 128]

# Question 2.2 (/1): What is the dimension of chatk3?
# Feel free to edit the number of dimensions.
convolutional_neural_networks_g_2_2: [N, 128]

# Question 3.1 (/1): How many parameters are there in Wfilter=3?
convolutional_neural_networks_g_3_1: 200*3*128 = 76800. (If bias needs to be included, it wd be 76800 + 128.)

# Question 3.2 (/1): How many parameters are there in Wfilter=4?
convolutional_neural_networks_g_3_2: 200*4*128 = 102400. (If bias needs to be included, it wd be 102400 + 128.)

# Question 3.3 (/1): How many parameters are there in Wfilter=5?
convolutional_neural_networks_g_3_3: 200*5*128 = 128000. (If bias needs to be included, it wd be 128000 + 128.)

# Question 3.4 (/1): How many parameters are there in Wout?
convolutional_neural_networks_g_3_4: 128*7 + bias = 896 + 7. (considering there is no hidden layer.)

# Question 4 (/1): Compare kernels to feature engineering.
# This question is a candidate for discussion in live session.
convolutional_neural_networks_g_4: feature extract and feature map

# Question 5.1 (/1): Would the two predictions be the same?
convolutional_neural_networks_g_5_1: No

# Question 5.2 (/1): Why or why not?
# This question is a candidate for discussion in live session.
convolutional_neural_networks_g_5_2: Due to convoluted layers, depending on window size dimensioanlity would be different.


# ------------------------------------------------------------------
# | Section (h): Implementing the CNN Model (10 points)  | 
# ------------------------------------------------------------------

# Code for question CNN_encoder (/10)


# ------------------------------------------------------------------
# | Section (i): Training and Evaluation (5 points)  | 
# ------------------------------------------------------------------

# Code for question Evaluation (/5)


# ------------------------------------------------------------------
# | Section (j): Tuning your model (3 points)  | 
# ------------------------------------------------------------------

# Question 1 (/1): Which method does the paper recommend?
# (This question is multiple choice.  Delete all but the correct answer(s)).
convolutional_neural_networks_j_1: 
 - random


# Question 2 (/1): Describe what you found.
# This question is a candidate for discussion in live session.
convolutional_neural_networks_j_2: your answer

# Question 3 (/1): Did you find they were the same?  Different?  (Are you overfitting the dev set?)
# This question is a candidate for discussion in live session.
convolutional_neural_networks_j_3: overfitting the dev set
